name: Daily Data Release

permissions:
  contents: write

on:
  schedule:
    - cron: "0 2 * * *" # runs every day at 06:00 UTC
  workflow_dispatch: # manual trigger if needed

jobs:
  build-and-release:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Prepare download folder
        run: mkdir -p downloads

      - name: Download OpenCellID
        env:
          API_KEY: ${{ secrets.OPENCELLID }}
        run: |
          curl -L "https://opencellid.org/ocid/downloads?token=$API_KEY&type=full&file=cell_towers.csv.gz" \
               -o downloads/cell_towers.csv.gz

      - name: Download OSM Surveillance Camera
        run: |
          #!/bin/bash
          set -e

          DOWNLOAD_URLS=(
            "http://overpass-api.de/api/interpreter"
            "https://maps.mail.ru/osm/tools/overpass/api/interpreter"
            "https://overpass.openstreetmap.ru/api/interpreter"
            "https://overpass.private.coffee/api/interpreter"
            "https://overpass.osm.jp/api/interpreter"
          )

          QUERY="%5Bout%3Ajson%5D%5Btimeout%3A3600%5D%3B%28node%5B%22man_made%22%3D%22surveillance%22%5D%3Bnode%5B%22surveillance%3Atype%22%3D%22camera%22%5D%3Bnode%5B%22surveillance%22%5D%3Bnode%5B%22camera%22%5D%3Bnode%5B%22highway%22%3D%22speed_camera%22%5D%3Bnode%5B%22man_made%22%3D%22speed_camera%22%5D%3Bnode%5B%22device%3Atype%22%3D%22camera%22%5D%3Bnode%5B%22cctv%22%3D%22yes%22%5D%3B%29%3Bout%20meta%3B"

          THRESHOLD=$((150 * 1024 * 1024)) # 150MB
          SUCCESS=0

          for URL in "${DOWNLOAD_URLS[@]}"; do
            echo "Trying $URL..."
            ATTEMPT=1

            while [ $ATTEMPT -le 2 ]; do
              FILE="downloads/osm_surveillance_cam.json"
              rm -f "$FILE"
              START_TIME=$(date +%s)

              # download
              curl -L --max-time 3600 "$URL?data=$QUERY" -o "$FILE" || true

              END_TIME=$(date +%s)
              DURATION=$((END_TIME - START_TIME))

              FILE_SIZE=$(stat -c%s "$FILE" 2>/dev/null || echo 0)

              # check if file is valid
              if [[ $FILE_SIZE -ge $THRESHOLD ]]; then
                echo "Download succeeded: $FILE_SIZE bytes"
                SUCCESS=1
                break 2
              fi

              # check for fast failure (<5min)
              if [[ $ATTEMPT -eq 1 && $DURATION -lt 300 ]]; then
                echo "Fast failure detected, retrying once on same instance..."
                ATTEMPT=$((ATTEMPT + 1))
              else
                echo "File too small ($FILE_SIZE bytes) or slow failure, moving to next instance..."
                break
              fi
            done
          done

          if [[ $SUCCESS -ne 1 ]]; then
            echo "All instances failed or returned too small files."
            exit 1
          fi
          
      - name: Download Submarine Cable
        run: |
          #!/bin/bash
          set -e
          echo "ðŸ“¡ Running submarine cable ingestor..."
          python3 scripts/submarine_cable_ingestor.py
          mv cable-geo-enriched.json downloads/

      - name: Download Terrestrial Cable
        run: |
          curl -L "https://bbmaps.itu.int/geoserver/ITU/ows?service=WFS&request=GetFeature&typeName=ITU:trx_public_2&outputFormat=application/json" \
               -o downloads/trx.json
               
      - name: Download World Airports
        run: |
          curl -k -L "https://ourairports.com/airports.csv" \
               -o downloads/airports.csv

      - name: Download Global Fishing Watch Ports
        run: |
          set -e
          echo "Installing Node.js 22.x, Git, and vt2geojson..."
          export DEBIAN_FRONTEND=noninteractive
          sudo apt-get update
          sudo apt-get install -y curl ca-certificates git
          curl -fsSL https://deb.nodesource.com/setup_22.x | sudo bash -
          sudo apt-get install -y nodejs
          sudo npm install -g @mapbox/vt2geojson
          
          echo "Downloading GFW Ports dataset..."
          tmp=$(mktemp)
          curl -sSL 'https://gateway.api.globalfishingwatch.org/v3/datasets/public-ports-v1/context-layers/0/0/0' \
               -H 'Origin: https://globalfishingwatch.org' \
               -H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:146.0) Gecko/20100101 Firefox/146.0' \
               -H 'Referer: https://globalfishingwatch.org/map/' \
               -o "$tmp"
          vt2geojson "$tmp" -z 0 -x 0 -y 0 > downloads/seaports.json
  
      - name: Publish rolling release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: daily-latest
          name: "Daily Dataset (latest)"
          body: "Automatically updated every day at 06:00 UTC."
          draft: false
          prerelease: false
          files: |
            downloads/cell_towers.csv.gz
            downloads/osm_surveillance_cam.json
            downloads/cable-geo-enriched.json
            downloads/trx.json
            downloads/airports.csv
            downloads/seaports.json
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
